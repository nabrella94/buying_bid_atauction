{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import warnings\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two auction lists of car for sales were uploaded in this project which were acceessable from IAAI.com,the digits in the file name\n",
    "show the date of auction\n",
    "reading the auction list file which is avaialble for public and dealer for a week before auction in  different barnches on https://www.iaai.com/LiveAuctions\n",
    "My target branch is in Detroit    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Documents/BranchSalesListItems_07082019.csv' does not exist: b'Documents/BranchSalesListItems_07082019.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-64f300e9c92b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfirst_automobile_auctionlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'Documents/BranchSalesListItems_07082019.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msecond_automobile_auctionlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'Documents/BranchSalesListItems_07252019.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Documents/BranchSalesListItems_07082019.csv' does not exist: b'Documents/BranchSalesListItems_07082019.csv'"
     ]
    }
   ],
   "source": [
    "first_automobile_auctionlist = pd.read_csv(r'Documents/BranchSalesListItems_07082019.csv')\n",
    "second_automobile_auctionlist = pd.read_csv(r'Documents/BranchSalesListItems_07252019.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate two files into a new file  and show list of all cars in auction avaliable for sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile=pd.concat([first_automobile_auctionlist, second_automobile_auctionlist], ignore_index=True)\n",
    "automobile.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing odemeters of autos  which has a nan value with zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automobile.Odometer=automobile.Odometer.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classified cars in 4 segments , we are looking to analyze the price of cars in Economy segment and adding this segment to \n",
    "pur data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automobile.insert(4, \"segment\",  True)\n",
    "def Classifysegment(make):\n",
    " \n",
    "    Midlevel = ['Alfa Romeo', 'RAM','Chrysler', 'Infiniti', 'MINI', 'Volkswagen' , 'JEEP','CADILLAC','LINCOLN']\n",
    "    Economy = ['TOYOTA' , 'HONDA','MAZDA' , 'CHEVROLET' , 'MERCURY','BUICK','SUBARU','VOLVO' ,'GMC','DODGE','KIA',\n",
    "               'Saab', 'PONTIAC' , 'NISSAN' ,'JEEP']\n",
    "    Luxury=['BMW','LEXSUS', 'MERCEDES-BENZ','PORSCHE','JAGUAR']\n",
    "    SuperLuxury=['BENTLEY' , 'MASARATI']\n",
    "   \n",
    "    if make in Midlevel:\n",
    "        return 'Midlevel'\n",
    "    if make in Economy:\n",
    "        return 'Economy'\n",
    "    if make in Luxury:\n",
    "        return 'Luxury'\n",
    "    elif make in SuperLuxury:\n",
    "        return 'SuperLuxury'\n",
    "    \n",
    "automobile['segment'] = [Classifysegment(make) for make in automobile.Make ]\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar char below shows destribution of car by make in the IAA auto auction from those lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "automobile.Make.value_counts().nlargest(10).plot(kind='bar', figsize=(15,5))\n",
    "plt.title(\"Number of vehicles by make\")\n",
    "plt.ylabel('Number of vehicles')\n",
    "plt.title('Disdtribution of car for sales in auction by brand', color='green', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conver Milage DataType from string to Intiger. Then rename some columns and then regarding my 2 years experince in busyning and selling cars\n",
    "filtering cars for sales in the auction to desirable list by some condition. This list  filter auction list to the most infuence for buyer targeting tax season cash \n",
    "no financing car with seler can sell them less than $5,000 with at least 25% profit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automobile.Odometer=automobile.Odometer.astype(str).str.replace(\",\", \"\").astype(int)\n",
    "\n",
    "automobile=automobile.rename(columns = {'Run & Drive':'Run','Sale Document':'SaleDoc','Primary Damage':'PrimaryDamage'\n",
    "                                        ,'Run & Drive':'Run','Secondary Damage':'SecondaryDamage'})\n",
    "\n",
    "df_filtered =automobile[(automobile.Odometer<= 160000 )&( automobile.Odometer > 80000 ) & (automobile.Starts == \"YES\")\n",
    "                        & (automobile.Run == \"YES\") & (automobile.segment == \"Economy\") & (automobile.Year<= 2011 ) \n",
    "                        & (automobile.Year>= 2005 ) & (automobile.SaleDoc.str.contains('CLEAR')) \n",
    "                        & (pd.notnull(automobile['Provider']))  & (automobile.PrimaryDamage !=\"LEFT REAR\") ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped unnecessary columns to reach the columns which make the most influence in buyer bid price , I want to \n",
    "these observations to machine to predict the price\n",
    "adding the price of car that sold in auction at bid price in the BidSalesPrices column , the goal af this is to \n",
    "train data for future prediction of car price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_filtered.drop(['segment','Starts','Run','Odometer Status','Lane','Item#','Auction Date','Public','Buy Now Price','Cylinders',\n",
    "                  'Fuel Type','Vehicle Location Info', 'Transmission','SaleDoc' ,'VIN','Loss Type' ,'Provider'],axis=1 ,\n",
    "                 inplace=True)\n",
    "df_filtered.insert(5, \"BidSalesPrices\",0)\n",
    "df_filtered.loc[:, \"BidSalesPrices\"] = [ 1050 , 1600 ,7000 , 1500 , 975 , 1700 , 1250 , 3450 ,1100, 1000 ,1850 \n",
    "                                         , 1500 , 1300 , 1450 , 700 , 800 , 1800 , 350 , 1400 , 1000, 800 ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating dictionary for damages of the cars which get to the accident , I rated the type accident from low to high cost what\n",
    "\n",
    "part of car get fixed from accident . IF it doesnot have an accident I rated that 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.SecondaryDamage = df_filtered.SecondaryDamage.replace(np.nan, 'nothing')\n",
    "PrimaryDamage = {'FRONT END': 1,'LEFT SIDE': 3,'FRONT & REAR':4 ,'LEFT & RIGHT':5 ,\\\n",
    "                 'REAR':6 ,'RIGHT REAR':7,'INTERIOR BURN':8  , 'RIGHT FRONT':9}\n",
    "\n",
    "SecondaryDamage = {'nothing':0,'FRONT END': 1,'REAR': 2,'RIGHT FRONT': 3,'LEFT SIDE':4 ,\\\n",
    "                   'FRONT & REAR':5 ,'LEFT & RIGHT':6 , 'RIGHT REAR':7,'INTERIOR BURN':8}\n",
    "\n",
    "df_filtered.loc[:, \"PrimaryDamage\"] = [PrimaryDamage[item] for item in df_filtered.PrimaryDamage]\n",
    "df_filtered.loc[:, \"SecondaryDamage\"] = [SecondaryDamage[item] for item in df_filtered.SecondaryDamage]\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "df_filtered.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction of bid sales price, using DecisionTree sklearn algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary modules and prediction\n",
    "\n",
    "\n",
    "# 1. Encoding\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "# 1. A. Encoding Make\n",
    "ls = le.fit(df_filtered['Make'].values)\n",
    "df_filtered['Make'] = ls.transform(df_filtered['Make'].values) \n",
    "# 1. B. Encoding Model\n",
    "le = le.fit(df_filtered['Model'].values)\n",
    "df_filtered['Model'] = le.transform(df_filtered['Model'].values) \n",
    "classifier = DecisionTreeClassifier()\n",
    "feature_cols = ['Year', 'Make', 'Model', 'Odometer','PrimaryDamage','SecondaryDamage']\n",
    "X = df_filtered[feature_cols] # Features\n",
    "y = df_filtered.BidSalesPrices # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "#df_trained =  pd.DataFrame([df_filtered.Year,df_filtered.Make,df_filtered.Model,df_filtered.Odometer,df_filtered.PrimaryDamage,df_filtered.SecondaryDamage ,df_filtered.BidSalesPrices]).transpose()\n",
    "#classifier = classifier.fit(df_trained, df_filtered['BidSalesPrices'])\n",
    "#pred = classifier.predict(df_trained)\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "print(y_pred)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "#print(df_filtered['BidSalesPrices'].to_string(index=False))\n",
    "\n",
    "X_train.shape\n",
    "X_train.head(6)\n",
    "\n",
    "y_train.shape\n",
    "y_train.head(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction of bid sales price, using kneithbour sklearn algorithm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2= KNeighborsClassifier(n_neighbors=3)\n",
    "classifier2 =classifier2.fit(X, y)\n",
    "prediction = classifier2.predict(X_test)\n",
    "print(prediction)\n",
    "# 2. Training\n",
    "#pred = svc_model.fit(df_filtered, df_filtered['$BidSalesPrices'])\n",
    "\n",
    " #3. Testing\n",
    "#pred = pred.predict(df_filtered)\n",
    "#print(\"LinearSVC accuracy : \",accuracy_score(df_filtered['BidSalesPrices'], pred, normalize = True))\n",
    "print(\"LinearSVC accuracy : \",accuracy_score(y_test, prediction, normalize = True))\n",
    "X_train.shape\n",
    "X_train.head(6)\n",
    "\n",
    "y_train.shape\n",
    "y_train.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
